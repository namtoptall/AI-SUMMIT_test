{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://bitbucket.org/dascim/acl2018_abssumm/src/master/README.md\n",
    "from datasets import load_dataset\n",
    "meetingbank = load_dataset(\"huuuyeah/meetingbank\")\n",
    "\n",
    "train_data = meetingbank['train']\n",
    "test_data = meetingbank['test']\n",
    "val_data = meetingbank['validation']\n",
    "\n",
    "def generator(data_split):\n",
    "  for instance in data_split:\n",
    "    yield instance['id'], instance['summary'], instance['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the first 2000 lines of the train transcripts\n",
    "all_transcripts = []\n",
    "for idx, (_, _, transcript) in enumerate(generator(train_data)):\n",
    "    all_transcripts.append(transcript)\n",
    "    if idx >= 1999:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/public_summary.txt'\n",
    "with open(output_path, \"w\") as file:\n",
    "    for transcript in all_transcripts:\n",
    "        file.write(transcript + \"\\n\\n\")\n",
    "\n",
    "# Return the path to the saved file\n",
    "output_path\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
